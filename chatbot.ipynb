{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, session\n",
    "from flask_session import Session\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import threading\n",
    "import time\n",
    "import requests\n",
    "import logging\n",
    "nltk.download('movie_reviews')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the movie reviews dataset\n",
    "documents = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids()]\n",
    "\n",
    "# preprocess documents\n",
    "tokenized_docs = [doc.lower().split() for doc in documents]\n",
    "\n",
    "# train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# generate embeddings for each document\n",
    "document_embeddings = []\n",
    "for doc in tokenized_docs:\n",
    "    doc_embedding = np.mean([w2v_model.wv[word] for word in doc if word in w2v_model.wv], axis=0)\n",
    "    document_embeddings.append(doc_embedding)\n",
    "document_embeddings = np.array(document_embeddings)\n",
    "\n",
    "# document database\n",
    "vector_db = {i: doc for i, doc in enumerate(documents)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s', handlers=[\n",
    "    logging.FileHandler(\"flask_app.log\"),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "\n",
    "# initialize the flash app\n",
    "app = Flask(__name__)\n",
    "app.config['SECRET_KEY'] = 'secretkey'\n",
    "app.config['SESSION_TYPE'] = 'filesystem'\n",
    "Session(app)\n",
    "\n",
    "# initialize the text generation pipeline, the LLM\n",
    "text_generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")\n",
    "\n",
    "# function to get the embedding of a query\n",
    "def get_embedding(text):\n",
    "    words = text.lower().split()\n",
    "    embedding = np.mean([w2v_model.wv[word] for word in words if word in w2v_model.wv], axis=0)\n",
    "    return embedding.reshape(1,-1)\n",
    "\n",
    "@app.route('/chat', methods=['POST'])\n",
    "def chat():\n",
    "    user_message = request.json.get('message')\n",
    "    logging.info(f\"Received message: {user_message}\")\n",
    "\n",
    "    if 'conversation' not in session:\n",
    "        session['conversation'] = []\n",
    "    \n",
    "    # store user message in the session\n",
    "    session['conversation'].append(user_message)\n",
    "\n",
    "    # convert query to embedding\n",
    "    query_embedding = get_embedding(user_message)\n",
    "\n",
    "    # compute cosine similarity between query and document embeddings\n",
    "    similarities = cosine_similarity(query_embedding, document_embeddings)\n",
    "\n",
    "    # retrieve the most similar documents\n",
    "    top_k_indices = np.argsort(similarities[0])[-5:][::-1]\n",
    "    retrieved_docs = [vector_db[idx] for idx in top_k_indices]\n",
    "\n",
    "    # concatenate retrieved documents and previous conversation\n",
    "    input_text = \" \".join(retrieved_docs) + \" \" + \" \".join(session['conversatioin'])\n",
    "\n",
    "    # generate response\n",
    "    response = text_generator(input_text)\n",
    "    generated_text = response[0]['generated_text']\n",
    "    logging.info(f\"Generated response: {generated_text}\")\n",
    "\n",
    "    # store bot response in the session\n",
    "    session['conversation'].append(generated_text)\n",
    "\n",
    "    return jsonify({'response': generated_text})\n",
    "\n",
    "@app.route('/reset', methods=['POST'])\n",
    "def reset():\n",
    "    session.pop('conversation', None)\n",
    "    logging.info(\"Conversation reset.\")\n",
    "    return jsonify({'message': 'Conversation reset.'})\n",
    "\n",
    "# function to run flask app\n",
    "def run_app():\n",
    "    app.run(port=5000, debug=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
